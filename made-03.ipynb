{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "import scipy.integrate as integrate\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "palette = sns.color_palette()\n",
    "figsize = (15,8)\n",
    "legend_fontsize = 16\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif'})\n",
    "rc('text', usetex=True)\n",
    "rc('text.latex',preamble=r'\\usepackage[utf8]{inputenc}')\n",
    "rc('text.latex',preamble=r'\\usepackage[russian]{babel}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полиномиальная регрессия и оверфиттинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Оверфиттинг\n",
    "## Исходная функция\n",
    "orig = lambda x : np.sin(2*x)\n",
    "\n",
    "## X-координаты точек данных\n",
    "xd = np.array([-3, -2, -1, -0.5, 0, 0.5, 1, 1.5, 2.5, 3, 4]) / 2\n",
    "num_points = len(xd)\n",
    "\n",
    "## Данные\n",
    "data = orig(xd) + np.random.normal(0, .25, num_points)\n",
    "\n",
    "## Для рисования\n",
    "xs = np.arange(xd[0]-1.5, xd[-1]+1.5, 0.01)\n",
    "\n",
    "## Обучаем модель с регуляризацией\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def train_model(xs, ys, alpha=0, use_lasso=False):\n",
    "    if alpha == 0:\n",
    "        return linear_model.LinearRegression(fit_intercept=True).fit( xs, ys )\n",
    "    else:\n",
    "        if use_lasso:\n",
    "            return linear_model.Lasso(alpha=alpha, fit_intercept=True).fit( xs, ys )\n",
    "        else:\n",
    "            return linear_model.Ridge(alpha=alpha, fit_intercept=True).fit( xs, ys )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Выделение полиномиальных признаков\n",
    "xs_d = np.vstack([xs ** i for i in range(1, num_points+1)]).transpose()\n",
    "xd_d = np.vstack([xd ** i for i in range(1, num_points+1)]).transpose()\n",
    "\n",
    "## Какие степени многочлена будем обучать и рисовать\n",
    "set_of_powers = [ 3, 10 ]\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((xs[0], xs[-1]))\n",
    "ax.set_ylim((-2, 2))\n",
    "ax.scatter(xd, data, marker='*', s=120)\n",
    "ax.plot(xs, orig(xs), linewidth=1, label=\"Исходная функция\", color=\"black\")\n",
    "\n",
    "for d in set_of_powers:\n",
    "    if d == 0:\n",
    "        print(np.mean(data))\n",
    "        ax.hlines(np.mean(data), xmin=xs[0], xmax=xs[-1], label=\"$d=0$\", linestyle=\"dashed\")\n",
    "    else:\n",
    "        cur_model = train_model( xd_d[:, :d], data )\n",
    "        print(cur_model.coef_)\n",
    "        ax.plot(xs, cur_model.predict( xs_d[:, :d] ), linewidth=2, label=\"$d=%d$\" % d)\n",
    "\n",
    "ax.legend(loc=\"upper center\", fontsize=legend_fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Байесовские предсказания в линейной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Исходная функция\n",
    "N = 250\n",
    "true_mu = [.5, -.5]\n",
    "def true_curve(x):\n",
    "    return true_mu[0] + true_mu[1]*x\n",
    "\n",
    "\n",
    "## X-координаты точек данных\n",
    "xd = np.array([-3, -2, -1, -0.5, 0, 0.5, 1, 1.5, 2.5, 3, 4]) / 2\n",
    "num_points = len(xd)\n",
    "\n",
    "## Данные\n",
    "data = true_curve(xd) + np.random.normal(0, .25, num_points)\n",
    "\n",
    "## Для рисования\n",
    "xs = np.arange(xd[0]-1.5, xd[-1]+1.5, 0.01)\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((xs[0], xs[-1]))\n",
    "ax.set_ylim((-2, 2))\n",
    "ax.plot(xs, true_curve(xs))\n",
    "ax.scatter(xd, data, marker='*', s=120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(-3, 3, N)\n",
    "X = np.linspace(-1, 1, N)\n",
    "Y = np.linspace(-1, 1, N)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "pos = np.empty(X.shape + (2,))\n",
    "pos[:, :, 0] = X\n",
    "pos[:, :, 1] = Y\n",
    "\n",
    "def myplot_heatmap(Z):\n",
    "    # Make the plot\n",
    "    plt.axis('equal')\n",
    "    plt.xlim((-1, 1))\n",
    "    plt.ylim((-1, 1))\n",
    "    plt.pcolormesh(X, Y, Z, cmap=plt.cm.jet)\n",
    "    plt.scatter(true_mu[0], true_mu[1], marker='*', s=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_mu, cur_sigma = np.array([0, 0]), 2*np.array([[1, 0], [0, 1]])\n",
    "\n",
    "Z = multivariate_normal.pdf(pos, mean=cur_mu, cov=cur_sigma)\n",
    "print(Z.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((xs[0], xs[-1]))\n",
    "ax.set_ylim((-2, 2))\n",
    "myplot_heatmap(Z)\n",
    "\n",
    "# plt.savefig(\"linregr_bayes1.png\", dpi=150, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myplot_sample_lines(mu, sigma, n=20, points=None):\n",
    "    # Посэмплируем и порисуем прямые\n",
    "    my_w = np.random.multivariate_normal(mu, sigma, n)\n",
    "\n",
    "    # plt.axis('equal')\n",
    "    for w in my_w:\n",
    "        plt.plot(xs, w[0] + w[1]*xs, 'k-', lw=.4)\n",
    "    plt.ylim((-3, 3))\n",
    "    plt.xlim((-3, 3))\n",
    "    if not points is None:\n",
    "        plt.scatter(points[0], points[1], marker='*', s=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((xs[0], xs[-1]))\n",
    "ax.set_ylim((-2, 2))\n",
    "myplot_sample_lines(cur_mu, cur_sigma, 200)\n",
    "# plt.savefig(\"linregr_bayes2.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_likelihood(px, py, sigma=.5):\n",
    "    return lambda x : np.exp(-(x[0] + x[1]*px - py) ** 2) / (2 * sigma * np.sqrt(2.*np.pi))\n",
    "\n",
    "px, py = xd[1], data[1]\n",
    "cur_likelihood = get_likelihood(px, py)\n",
    "Z = np.array([[ cur_likelihood(pos[i, j]) for j in range(pos.shape[1])] for i in range(pos.shape[0])])\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((xs[0], xs[-1]))\n",
    "ax.set_ylim((-2, 2))\n",
    "myplot_heatmap(Z)\n",
    "\n",
    "# plt.savefig(\"linregr_bayes3.png\", dpi=150, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_update(mu, sigma, x, y, sigma_noise=.25):\n",
    "    x_matrix = np.array([[1, x]])\n",
    "    sigma_n = np.linalg.inv(np.linalg.inv(sigma)+ (1 / (sigma_noise ** 2)) * np.matmul(np.transpose(x_matrix), x_matrix) )\n",
    "    mu_n = np.matmul(sigma_n, np.matmul(np.linalg.inv(sigma), np.transpose(mu)) + (1 / (sigma_noise ** 2)) * np.matmul(np.transpose(x_matrix), np.array([y]) ) )\n",
    "    return mu_n, sigma_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_mu, cur_sigma = bayesian_update(cur_mu, cur_sigma, px, py)\n",
    "Z = multivariate_normal.pdf(pos, mean=cur_mu, cov=cur_sigma)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((xs[0], xs[-1]))\n",
    "ax.set_ylim((-2, 2))\n",
    "myplot_heatmap(Z)\n",
    "\n",
    "# plt.savefig(\"linregr_bayes4.png\", dpi=150, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посэмплируем и порисуем прямые\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((xs[0], xs[-1]))\n",
    "ax.set_ylim((-2, 2))\n",
    "myplot_sample_lines(cur_mu, cur_sigma, 20, points=[[px], [py]])\n",
    "# plt.savefig(\"linregr_bayes5.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посэмплируем прямые и выдадим статистики по предсказаниям\n",
    "def sample_statistics(mu, sigma, xs, n=20):\n",
    "    my_w = np.random.multivariate_normal(mu, sigma, n)\n",
    "    res = np.zeros((n, xs.shape[0]))\n",
    "    for i,w in enumerate(my_w):\n",
    "        res[i,:] = w[0] + w[1]*xs\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нарисуем результат\n",
    "def plot_predictions(xs, mu, x, points):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim((xs[0], xs[-1]))\n",
    "    ax.set_ylim((-2, 2))\n",
    "    ax.plot(xs, true_curve(xs), label=\"Правильный ответ\")\n",
    "    ax.plot(xs, mu[1]*xs + mu[0], color=\"red\", label=\"MAP гипотеза\")\n",
    "    ax.fill_between(xs, mu[1]*xs + mu[0] - .25, mu[1]*xs + mu[0] + .25, color=palette[1], alpha=.3, label=\"+- дисперсия шума\")\n",
    "    ax.fill_between(xs, np.mean(x, axis=0) - np.std(x, axis=0), np.mean(x, axis=0) + np.std(x, axis=0), color=palette[5], alpha=.2, label=\"+- дисперсия предсказаний\")\n",
    "    ax.scatter(points[0], points[1], marker='*', s=200)\n",
    "    ax.legend(fontsize=legend_fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample_statistics(cur_mu, cur_sigma, xs, n=1000)\n",
    "plot_predictions(xs, cur_mu, x, [[px], [py]])\n",
    "# plt.savefig(\"linregr_bayes6.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px2, py2 = xd[7], data[7]\n",
    "cur_likelihood = get_likelihood(px2, py2)\n",
    "Z = np.array([[ cur_likelihood(pos[i, j]) for j in range(pos.shape[1])] for i in range(pos.shape[0])])\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((xs[0], xs[-1]))\n",
    "ax.set_ylim((-2, 2))\n",
    "myplot_heatmap(Z)\n",
    "\n",
    "# plt.savefig(\"linregr_bayes7.png\", dpi=150, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_mu, cur_sigma = bayesian_update(cur_mu, cur_sigma, px2, py2)\n",
    "Z = multivariate_normal.pdf(pos, mean=cur_mu, cov=cur_sigma)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((xs[0], xs[-1]))\n",
    "ax.set_ylim((-2, 2))\n",
    "myplot_heatmap(Z)\n",
    "\n",
    "# plt.savefig(\"linregr_bayes8.png\", dpi=150, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посэмплируем и порисуем прямые\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((xs[0], xs[-1]))\n",
    "ax.set_ylim((-2, 2))\n",
    "myplot_sample_lines(cur_mu, cur_sigma, n=20, points=[[px, px2], [py, py2]])\n",
    "# plt.savefig(\"linregr_bayes9.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample_statistics(cur_mu, cur_sigma, xs, n=2000)\n",
    "plot_predictions(xs, cur_mu, x, [[px, px2], [py, py2]])\n",
    "# plt.savefig(\"linregr_bayes10.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px3, py3 = xd[3], data[3]\n",
    "cur_likelihood = get_likelihood(px3, py3)\n",
    "Z = np.array([[ cur_likelihood(pos[i, j]) for j in range(pos.shape[1])] for i in range(pos.shape[0])])\n",
    "myplot_heatmap(Z)\n",
    "plt.show()\n",
    "cur_mu, cur_sigma = bayesian_update(cur_mu, cur_sigma, px3, py3)\n",
    "Z = multivariate_normal.pdf(pos, mean=cur_mu, cov=cur_sigma)\n",
    "myplot_heatmap(Z)\n",
    "plt.show()\n",
    "myplot_sample_lines(cur_mu, cur_sigma, n=200, points=[[px, px2, px3], [py, py2, py3]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample_statistics(cur_mu, cur_sigma, xs, n=2000)\n",
    "plot_predictions(xs, cur_mu, x, [[px, px2, px3], [py, py2, py3]])\n",
    "# plt.savefig(\"linregr_bayes10.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Статистическая теория принятия решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "alpha = 0.00001\n",
    "use_lasso = True\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((xs[0], xs[-1]))\n",
    "ax.set_ylim((-3, 3))\n",
    "\n",
    "res = []\n",
    "for _ in range(N):\n",
    "    cur_data = orig(xd) + np.random.normal(0, .25, num_points)\n",
    "    cur_model = train_model(xd_d, cur_data, alpha, use_lasso)\n",
    "    res.append(cur_model.predict( xs_d ))\n",
    "    ax.plot(xs, res[-1], linewidth=.1, color=\"0.5\")\n",
    "\n",
    "ax.plot(xs, orig(xs), linewidth=2, label=\"Исходная функция\", color=palette[0])\n",
    "ax.scatter(xd, orig(xd), marker='*', s=150, color=palette[0])\n",
    "\n",
    "ax.plot(xs, np.mean( res, axis=0 ), linewidth=2, label=\"Усреднённые предсказания\", color=\"red\")\n",
    "ax.legend(loc=\"upper center\", fontsize=legend_fontsize)\n",
    "plt.show()\n",
    "\n",
    "cur_model = linear_model.LinearRegression(fit_intercept=True).fit( xd_d[:, :d], data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_size = 30\n",
    "test_set_x = np.random.rand(test_set_size) * (2 + 1.5) - 1.5\n",
    "test_set_xs = np.vstack([test_set_x ** i for i in range(1, 12)]).transpose()\n",
    "print(test_set_xs.shape)\n",
    "test_set_y = orig(test_set_xs[:,0]) + np.random.normal(0, .25, test_set_size)\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(xs, orig(xs), linewidth=2, label=\"Исходная функция\", color=palette[0])\n",
    "ax.scatter(test_set_xs[:,0], test_set_y, marker='*', s=150, color=palette[0])\n",
    "ax.set_xlim((-1.5, 2))\n",
    "\n",
    "def test_set_error(model, d):\n",
    "    return np.mean( (test_set_y - model.predict(test_set_xs[:, :d])) ** 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "use_lasso=False\n",
    "alphas = np.logspace(-4, 2, num=20)\n",
    "errors, biases, variances = [], [], []\n",
    "for alpha in alphas:\n",
    "    res, res_preds, res_test = [], [], []\n",
    "    for _ in range(N):\n",
    "        cur_data = orig(xd) + np.random.normal(0, .25, num_points)\n",
    "        cur_model = train_model(xd_d, cur_data, alpha, use_lasso)\n",
    "        res.append(test_set_error(cur_model, xd_d.shape[1]))\n",
    "        res_test.append(cur_model.predict(test_set_xs))\n",
    "        res_preds.append(cur_model.predict( xs_d ))\n",
    "    res_test = np.array(res_test)\n",
    "    avg_preds = np.mean(res_test, axis=0)\n",
    "    errors.append(np.mean(res))\n",
    "    biases.append(np.mean((avg_preds-orig(test_set_x))**2))\n",
    "    variances.append(np.mean((res_test-avg_preds)**2))\n",
    "    print(\"alpha = %.6f\\tmean error = %.6f\\tbias = %.6f\\tvariance = %.6f\" % (alpha, errors[-1], biases[-1], variances[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "# plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "ax.plot(alphas, biases, linewidth=2, label=\"Bias\")\n",
    "ax.plot(alphas, variances, linewidth=2, label=\"Variance\")\n",
    "ax.plot(alphas, np.array(biases) + np.array(variances), linewidth=2, label=\"Bias + Variance\")\n",
    "ax.plot(alphas, errors, linewidth=2, label=\"Ошибка на тестовом множестве\", color=\"black\")\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_xlim((0.001, 100))\n",
    "ax.legend(fontsize=legend_fontsize)\n",
    "# fig.savefig('statdecision1.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эквивалентное ядро в линейной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 1\n",
    "x_pred = 1\n",
    "\n",
    "new_data = np.copy(data)\n",
    "new_data[7] = 0\n",
    "cur_model = linear_model.LinearRegression(fit_intercept=True).fit( xd_d[:, :d], new_data )\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((xs[0], xs[-1]))\n",
    "ax.set_ylim((-2, 2))\n",
    "ax.scatter(xd, new_data, marker='*', s=120)\n",
    "ax.plot(xs, orig(xs), linewidth=1, label=\"Исходная функция\", color=\"black\")\n",
    "ax.plot(xs, cur_model.predict( xs_d[:, :d] ), linewidth=2, label=\"$d=%d$\" % d)\n",
    "y_pred = cur_model.predict(np.array([x_pred]).reshape(1,-1))\n",
    "ax.scatter(x_pred, y_pred, marker='*', s=200)\n",
    "\n",
    "\n",
    "print(data)\n",
    "print(new_data)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_prediction(x_pred, cur_y, d=1, data_ind=7, data=data):\n",
    "    new_data = np.copy(data)\n",
    "    new_data[data_ind] = cur_y\n",
    "    cur_model = linear_model.LinearRegression(fit_intercept=True).fit( xd_d[:, :d], new_data )\n",
    "    return cur_model.predict(np.array([x_pred]).reshape(1,-1))[0]\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "ys = np.arange(-1, 1, 0.1)\n",
    "ax.set_xlim((ys[0], ys[-1]))\n",
    "\n",
    "for x_pred in [-.5, 1, 1.5, 2]:\n",
    "    one_pred = [ get_one_prediction(x_pred, y) for y in ys ]\n",
    "    ax.plot(ys, one_pred, linewidth=1, label=\"Предсказание в точке %.2f\" % x_pred)\n",
    "\n",
    "ax.legend(fontsize=legend_fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
